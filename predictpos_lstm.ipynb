{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039d58f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 16:15:42.219599: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import brown, treebank, conll2000\n",
    "\n",
    "brown_sent = brown.tagged_sents(tagset='universal')\n",
    "tree_sent = treebank.tagged_sents(tagset='universal')\n",
    "conll_sent = conll2000.tagged_sents(tagset='universal')\n",
    "all_sent = brown_sent + tree_sent + conll_sent\n",
    "pos = [[pos[1] for pos in tup] for tup in all_sent] # store the corresponding pos tag\n",
    "pos_tokenizer = Tokenizer()\n",
    "pos_tokenizer.fit_on_texts(pos)\n",
    "pos_seqs = pos_tokenizer.texts_to_sequences(pos)\n",
    "\n",
    "f = open('data/data_normal.txt')\n",
    "lines = f.readlines()\n",
    "data = []\n",
    "for line in lines:\n",
    "    tokens = line.split()\n",
    "    tokens =  [t.lower() for t in tokens]\n",
    "    data.append(tokens)\n",
    "\n",
    "f_out = open('data/labels_normal.txt')\n",
    "lines_out = f_out.readlines()\n",
    "labels = []\n",
    "for line in lines_out:\n",
    "    tokens = line.split()\n",
    "    labels.append(tokens)\n",
    "    \n",
    "f = open('data/data_garden.txt')\n",
    "lines = f.readlines()\n",
    "garden_data = []\n",
    "for line in lines:\n",
    "    tokens = line.split()\n",
    "    tokens =  [t.lower() for t in tokens]\n",
    "    garden_data.append(tokens)\n",
    "\n",
    "f_out = open('data/labels_garden.txt')\n",
    "lines_out = f_out.readlines()\n",
    "garden_labels = []\n",
    "for line in lines_out:\n",
    "    tokens = line.split()\n",
    "    garden_labels.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb9181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    accuracies = []\n",
    "    for i in range(len(preds)):\n",
    "        actual = labels[i]\n",
    "        predict = preds[i]\n",
    "        acc = 0\n",
    "        for j in range(len(predict)):\n",
    "            try:\n",
    "                if predict[j] == actual[j]:\n",
    "                    acc += 1\n",
    "            except:\n",
    "                print('Line:', i)\n",
    "                print('Predict:', len(predict))\n",
    "                print('Actual:', len(actual))\n",
    "        if len(preds[i]) > 0:\n",
    "            acc = acc / len(preds[i])\n",
    "        accuracies.append(acc)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01cffb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, sent_type):\n",
    "    if sent_type == 'normal':\n",
    "        pred = model.predict(normal_pd)\n",
    "        pred_vec = np.argmax(pred, axis =-1)\n",
    "        label = np.argmax(normal_pos_pd,axis =-1)\n",
    "        pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "        inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "        actual_length = len((np.where(actual_flat != 0))[0])\n",
    "        print(len(inds[0])/len(pred_flat))\n",
    "    else:\n",
    "        pred = model.predict(garden_pd)\n",
    "        pred_vec = np.argmax(pred, axis =-1)\n",
    "        label = np.argmax(garden_pos_pd,axis =-1)\n",
    "        pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "        inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "        actual_length = len((np.where(actual_flat != 0))[0])\n",
    "        print(len(inds[0])/len(pred_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58cf218",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 10\n",
    "\n",
    "normal_tokenizer = Tokenizer()\n",
    "garden_tokenizer = Tokenizer()\n",
    "normal_tokenizer.fit_on_texts(data)\n",
    "garden_tokenizer.fit_on_texts(garden_data)\n",
    "normal = normal_tokenizer.texts_to_sequences(data)\n",
    "garden = garden_tokenizer.texts_to_sequences(garden_data)\n",
    "normal_pd = pad_sequences(normal, max_len, padding='post', truncating='post')\n",
    "garden_pd = pad_sequences(garden, max_len, padding='post', truncating='post')\n",
    "\n",
    "pos_tokenizer = Tokenizer()\n",
    "pos_tokenizer.fit_on_texts(labels)\n",
    "pos_tokenizer.fit_on_texts(garden_labels)\n",
    "normal_pos = pos_tokenizer.texts_to_sequences(labels)\n",
    "garden_pos = pos_tokenizer.texts_to_sequences(garden_labels)\n",
    "normal_pos_pd = pad_sequences(normal_pos, max_len, padding='post', truncating='post')\n",
    "garden_pos_pd = pad_sequences(garden_pos, max_len, padding='post', truncating='post')\n",
    "normal_pos_pd = to_categorical(normal_pos_pd, num_classes=13)\n",
    "garden_pos_pd = to_categorical(garden_pos_pd, num_classes=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "275a3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASKED = load_model('lstm_lr0.0005_bs128_pd100_e20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28892cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 13.1387 - accuracy: 0.0748\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 13.9822 - accuracy: 0.0331\n"
     ]
    }
   ],
   "source": [
    "MASKED_res = MASKED.evaluate(normal_pd, normal_pos_pd)\n",
    "MASKED_resGarden = MASKED.evaluate(garden_pd, garden_pos_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "488a3858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "0.07482993197278912\n",
      "LSTM Model with Mask True\n",
      "Normal Sentence: \"The old man rode the boat\"\n",
      "Prediction:  ['ADJ', 'VERBS', 'ADV', '.', 'ADJ', 'ADJ', 'DET']\n",
      "Actual:  ['DET', 'ADJ', 'NOUN', 'VERB', 'DET', 'NOUN', '.']\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "0.033112582781456956\n",
      "Garden Path Sentence: \"The old man the boat\"\n",
      "Prediction:  ['ADJ', 'DET', '.', 'ADJ', 'DET', 'DET']\n",
      "Actual:  ['DET', 'NOUN', 'VERB', 'DET', 'NOUN', '.']\n"
     ]
    }
   ],
   "source": [
    "pred = MASKED.predict(normal_pd) \n",
    "pred_vec = np.argmax(pred, axis =-1)\n",
    "label = np.argmax(normal_pos_pd,axis =-1)\n",
    "pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "actual_length = len((np.where(actual_flat != 0))[0])\n",
    "# print(pred_vec[:5]) \n",
    "# print(label[:5])\n",
    "print(len(inds[0])/actual_length)\n",
    "# \n",
    "all_posttags = []\n",
    "for p in pred:\n",
    "    predseq = [np.argmax(pred, axis=-1) for pred in p]\n",
    "    pred_tags = [pos_tokenizer.sequences_to_texts([[i]])[0].upper() for i in predseq]\n",
    "    all_posttags.append(pred_tags)\n",
    "print('LSTM Model with Mask True')\n",
    "print('Normal Sentence: \"The old man rode the boat\"')\n",
    "print(\"Prediction: \", all_posttags[:1][:6][0][:7])\n",
    "print('Actual: ', labels[0])\n",
    "\n",
    "\n",
    "pred = MASKED.predict(garden_pd) \n",
    "pred_vec = np.argmax(pred, axis =-1)\n",
    "label = np.argmax(garden_pos_pd,axis =-1)\n",
    "pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "actual_length = len((np.where(actual_flat != 0))[0])\n",
    "# print(pred_vec[:5]) \n",
    "# print(label[:5])\n",
    "print(len(inds[0])/actual_length)\n",
    "\n",
    "all_posttags = []\n",
    "for p in pred:\n",
    "    predseq = [np.argmax(pred, axis=-1) for pred in p]\n",
    "    pred_tags = [pos_tokenizer.sequences_to_texts([[i]])[0].upper() for i in predseq]\n",
    "    all_posttags.append(pred_tags)\n",
    "print('Garden Path Sentence: \"The old man the boat\"')\n",
    "print(\"Prediction: \", all_posttags[:1][0][:6])\n",
    "print('Actual: ', garden_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1910da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 653ms/step - loss: 4.0615 - accuracy: 0.3143\n",
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd2e203f9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.9192 - accuracy: 0.3524\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd2b4aa4d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 2.2467 - accuracy: 0.1810\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.4386 - accuracy: 0.2476\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.0344 - accuracy: 0.3095\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.2206 - accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "lr01_pd10 = load_model('lstm_lr0.1_bs128_p10_e20_sgd.h5')\n",
    "lr001_pd10 = load_model('lstm_lr0.01_bs128_p10_e20_sgd.h5')\n",
    "lr0001_pd10 = load_model('lstm_lr0.001_bs128_p10_e20_sgd.h5')\n",
    "lr01_pd10_res = lr01_pd10.evaluate(normal_pd, normal_pos_pd)\n",
    "lr001_pd10_res = lr001_pd10.evaluate(normal_pd, normal_pos_pd)\n",
    "lr0001_pd10_res = lr0001_pd10.evaluate(normal_pd, normal_pos_pd)\n",
    "lr01_pd10_resGarden = lr01_pd10.evaluate(garden_pd, garden_pos_pd)\n",
    "lr001_pd10_resGarden = lr001_pd10.evaluate(garden_pd, garden_pos_pd)\n",
    "lr0001_pd10_resGarden = lr0001_pd10.evaluate(garden_pd, garden_pos_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1656687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 318ms/step\n",
      "0.09523809523809523\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "0.11904761904761904\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "0.18095238095238095\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "0.06666666666666667\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "0.11428571428571428\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "prediction(lr01_pd10, 'normal')\n",
    "prediction(lr001_pd10, 'normal')\n",
    "prediction(lr0001_pd10, 'normal')\n",
    "prediction(lr01_pd10, 'garden')\n",
    "prediction(lr001_pd10, 'garden')\n",
    "prediction(lr0001_pd10, 'garden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9fd2666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 348ms/step - loss: 0.6428 - accuracy: 0.8600\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.3381 - accuracy: 0.8845\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.4920 - accuracy: 0.8818\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6908 - accuracy: 0.8524\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3450 - accuracy: 0.8838\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5062 - accuracy: 0.8781\n"
     ]
    }
   ],
   "source": [
    "lr01_pd50 = load_model('lstm_lr0.1_bs128_p50_e20_sgd.h5')\n",
    "lr001_pd50 = load_model('lstm_lr0.01_bs128_p50_e20_sgd.h5')\n",
    "lr0001_pd50 = load_model('lstm_lr0.001_bs128_p50_e20_sgd.h5')\n",
    "lr01_pd50_res = lr01_pd50.evaluate(normal_pd, normal_pos_pd)\n",
    "lr001_pd50_res = lr001_pd50.evaluate(normal_pd, normal_pos_pd)\n",
    "lr0001_pd50_res = lr0001_pd50.evaluate(normal_pd, normal_pos_pd)\n",
    "lr01_pd50_resGarden = lr01_pd50.evaluate(garden_pd, garden_pos_pd)\n",
    "lr001_pd50_resGarden = lr001_pd50.evaluate(garden_pd, garden_pos_pd)\n",
    "lr0001_pd50_resGarden = lr0001_pd50.evaluate(garden_pd, garden_pos_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa4acd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 468ms/step - loss: 0.2628 - accuracy: 0.9319\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1828 - accuracy: 0.9443\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.2541 - accuracy: 0.9333\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2827 - accuracy: 0.9257\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1869 - accuracy: 0.9424\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2624 - accuracy: 0.9310\n"
     ]
    }
   ],
   "source": [
    "lr01_pd100 = load_model('lstm_lr0.1_bs128_p100_e20_sgd.h5')\n",
    "lr001_pd100 = load_model('lstm_lr0.01_bs128_p100_e20_sgd.h5')\n",
    "lr0001_pd100 = load_model('lstm_lr0.001_bs128_p100_e20_sgd.h5')\n",
    "lr01_pd100_res = lr01_pd100.evaluate(normal_pd, normal_pos_pd)\n",
    "lr001_pd100_res = lr001_pd100.evaluate(normal_pd, normal_pos_pd)\n",
    "lr0001_pd100_res = lr0001_pd100.evaluate(normal_pd, normal_pos_pd)\n",
    "lr01_pd100_resGarden = lr01_pd100.evaluate(garden_pd, garden_pos_pd)\n",
    "lr001_pd100_resGarden = lr001_pd100.evaluate(garden_pd, garden_pos_pd)\n",
    "lr0001_pd100_resGarden = lr0001_pd100.evaluate(garden_pd, garden_pos_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "989b968c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 292ms/step\n",
      "LSTM Model with Mask False Padding 10\n",
      "Normal Sentence: \"The old man rode the boat\"\n",
      "Prediction:  ['NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual:  ['DET', 'ADJ', 'NOUN', 'VERB', 'DET', 'NOUN', '.']\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Garden Path Sentence: \"The old man the boat\"\n",
      "Prediction:  ['NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual:  ['DET', 'NOUN', 'VERB', 'DET', 'NOUN', '.']\n"
     ]
    }
   ],
   "source": [
    "pred = lr0001_pd10.predict(normal_pd) \n",
    "pred_vec = np.argmax(pred, axis =-1)\n",
    "label = np.argmax(normal_pos_pd,axis =-1)\n",
    "pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "\n",
    "# print(len(inds[0])/len(pred_flat))\n",
    "\n",
    "all_posttags = []\n",
    "for p in pred:\n",
    "    predseq = [np.argmax(pred, axis=-1) for pred in p]\n",
    "    pred_tags = [pos_tokenizer.sequences_to_texts([[i]])[0].upper() for i in predseq]\n",
    "    all_posttags.append(pred_tags)\n",
    "print('LSTM Model with Mask False Padding 10')\n",
    "print('Normal Sentence: \"The old man rode the boat\"')\n",
    "print(\"Prediction: \", all_posttags[:1][0][:6])\n",
    "print('Actual: ', labels[0])\n",
    "\n",
    "\n",
    "pred = lr0001_pd10.predict(garden_pd) \n",
    "pred_vec = np.argmax(pred, axis =-1)\n",
    "label = np.argmax(garden_pos_pd,axis =-1)\n",
    "pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "inds = np.where((pred_flat == actual_flat) & (actual_flat != 0))\n",
    "# print(pred_vec) \n",
    "# print(label)\n",
    "# print(len(inds[0])/len(pred_flat))\n",
    "\n",
    "all_posttags = []\n",
    "for p in pred:\n",
    "    predseq = [np.argmax(pred, axis=-1) for pred in p]\n",
    "    pred_tags = [pos_tokenizer.sequences_to_texts([[i]])[0].upper() for i in predseq]\n",
    "    all_posttags.append(pred_tags)\n",
    "print('Garden Path Sentence: \"The old man the boat\"')\n",
    "print(\"Prediction: \", all_posttags[:1][0][:6])\n",
    "print('Actual: ', garden_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ba86add1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2781456953642384\n"
     ]
    }
   ],
   "source": [
    "test = np.where(label== 1)\n",
    "len_test = len(test[0])/len((np.where(actual_flat != 0))[0])\n",
    "print(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c75b7858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "(21, 10, 13)\n"
     ]
    }
   ],
   "source": [
    "print(len(test[0]))\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304e7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
