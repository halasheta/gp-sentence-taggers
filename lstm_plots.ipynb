{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "039d58f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import brown, treebank, conll2000\n",
    "\n",
    "brown_sent = brown.tagged_sents(tagset='universal')\n",
    "tree_sent = treebank.tagged_sents(tagset='universal')\n",
    "conll_sent = conll2000.tagged_sents(tagset='universal')\n",
    "all_sent = brown_sent + tree_sent + conll_sent\n",
    "pos = [[pos[1] for pos in tup] for tup in all_sent] # store the corresponding pos tag\n",
    "pos_tokenizer = Tokenizer()\n",
    "pos_tokenizer.fit_on_texts(pos)\n",
    "pos_seqs = pos_tokenizer.texts_to_sequences(pos)\n",
    "\n",
    "f = open('data/data_normal.txt')\n",
    "lines = f.readlines()\n",
    "data = []\n",
    "for line in lines:\n",
    "    tokens = line.split()\n",
    "    tokens =  [t.lower() for t in tokens]\n",
    "    data.append(tokens)\n",
    "\n",
    "f_out = open('data/labels_normal.txt')\n",
    "lines_out = f_out.readlines()\n",
    "labels = []\n",
    "for line in lines_out:\n",
    "    tokens = line.split()\n",
    "    labels.append(tokens)\n",
    "    \n",
    "f = open('data/data_garden.txt')\n",
    "lines = f.readlines()\n",
    "garden_data = []\n",
    "for line in lines:\n",
    "    tokens = line.split()\n",
    "    tokens =  [t.lower() for t in tokens]\n",
    "    garden_data.append(tokens)\n",
    "\n",
    "f_out = open('data/labels_garden.txt')\n",
    "lines_out = f_out.readlines()\n",
    "garden_labels = []\n",
    "for line in lines_out:\n",
    "    tokens = line.split()\n",
    "    garden_labels.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fb9181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    accuracies = []\n",
    "    for i in range(len(preds)):\n",
    "        actual = labels[i]\n",
    "        predict = preds[i]\n",
    "        acc = 0\n",
    "        for j in range(len(predict)):\n",
    "            try:\n",
    "                if predict[j] == actual[j]:\n",
    "                    acc += 1\n",
    "            except:\n",
    "                print('Line:', i)\n",
    "                print('Predict:', len(predict))\n",
    "                print('Actual:', len(actual))\n",
    "        if len(preds[i]) > 0:\n",
    "            acc = acc / len(preds[i])\n",
    "        accuracies.append(acc)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01cffb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, sent_type):\n",
    "    if sent_type == 'normal':\n",
    "        pred = model.predict(normal_pd)\n",
    "        pred_vec = np.argmax(pred, axis =-1)\n",
    "        label = np.argmax(normal_pos_pd,axis =-1)\n",
    "        pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "        inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "        print(len(inds[0])/len(pred_flat))\n",
    "    else:\n",
    "        pred = model.predict(garden_pd)\n",
    "        pred_vec = np.argmax(pred, axis =-1)\n",
    "        label = np.argmax(garden_pos_pd,axis =-1)\n",
    "        pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "        inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "        print(len(inds[0])/len(pred_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b58cf218",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "\n",
    "normal_tokenizer = Tokenizer()\n",
    "garden_tokenizer = Tokenizer()\n",
    "normal_tokenizer.fit_on_texts(data)\n",
    "garden_tokenizer.fit_on_texts(garden_data)\n",
    "normal = normal_tokenizer.texts_to_sequences(data)\n",
    "garden = garden_tokenizer.texts_to_sequences(garden_data)\n",
    "normal_pd = pad_sequences(normal, max_len, padding='post', truncating='post')\n",
    "garden_pd = pad_sequences(garden, max_len, padding='post', truncating='post')\n",
    "\n",
    "pos_tokenizer = Tokenizer()\n",
    "pos_tokenizer.fit_on_texts(labels)\n",
    "pos_tokenizer.fit_on_texts(garden_labels)\n",
    "normal_pos = pos_tokenizer.texts_to_sequences(labels)\n",
    "garden_pos = pos_tokenizer.texts_to_sequences(garden_labels)\n",
    "normal_pos_pd = pad_sequences(normal_pos, max_len, padding='post', truncating='post')\n",
    "garden_pos_pd = pad_sequences(garden_pos, max_len, padding='post', truncating='post')\n",
    "normal_pos_pd = to_categorical(normal_pos_pd, num_classes=13)\n",
    "garden_pos_pd = to_categorical(garden_pos_pd, num_classes=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "275a3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASKED = load_model('lstm_lr0.0005_bs128_pd100_e20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28892cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 994ms/step - loss: 13.1162 - accuracy: 0.0645\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.9822 - accuracy: 0.0331\n"
     ]
    }
   ],
   "source": [
    "MASKED_res = MASKED.evaluate(normal_pd, normal_pos_pd)\n",
    "MASKED_resGarden = MASKED.evaluate(garden_pd, garden_pos_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "488a3858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "LSTM Model with Mask True\n",
      "Normal Sentence: \"The old man rode the boat\"\n",
      "Prediction:  ['ADJ', 'VERBS', 'ADV', '.', 'ADJ', 'ADJ', 'DET']\n",
      "Actual:  ['DET', 'ADJ', 'NOUN', 'VERB', 'DET', 'NOUN', '.']\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Garden Path Sentence: \"The old man the boat\"\n",
      "Prediction:  ['ADJ', 'DET', '.', 'ADJ', 'DET', 'DET']\n",
      "Actual:  ['DET', 'NOUN', 'VERB', 'DET', 'NOUN', '.']\n"
     ]
    }
   ],
   "source": [
    "pred = MASKED.predict(normal_pd) \n",
    "pred_vec = np.argmax(pred, axis =-1)\n",
    "label = np.argmax(normal_pos_pd,axis =-1)\n",
    "pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "# print(pred_vec[:5]) \n",
    "# print(label[:5])\n",
    "# print(len(inds[0])/len(pred_flat))\n",
    "# \n",
    "all_posttags = []\n",
    "for p in pred:\n",
    "    predseq = [np.argmax(pred, axis=-1) for pred in p]\n",
    "    pred_tags = [pos_tokenizer.sequences_to_texts([[i]])[0].upper() for i in predseq]\n",
    "    all_posttags.append(pred_tags)\n",
    "print('LSTM Model with Mask True')\n",
    "print('Normal Sentence: \"The old man rode the boat\"')\n",
    "print(\"Prediction: \", all_posttags[:1][:6][0][:7])\n",
    "print('Actual: ', labels[0])\n",
    "\n",
    "\n",
    "pred = MASKED.predict(garden_pd) \n",
    "pred_vec = np.argmax(pred, axis =-1)\n",
    "label = np.argmax(garden_pos_pd,axis =-1)\n",
    "pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "# print(pred_vec[:5]) \n",
    "# print(label[:5])\n",
    "# print(len(inds[0])/len(pred_flat))\n",
    "\n",
    "all_posttags = []\n",
    "for p in pred:\n",
    "    predseq = [np.argmax(pred, axis=-1) for pred in p]\n",
    "    pred_tags = [pos_tokenizer.sequences_to_texts([[i]])[0].upper() for i in predseq]\n",
    "    all_posttags.append(pred_tags)\n",
    "print('Garden Path Sentence: \"The old man the boat\"')\n",
    "print(\"Prediction: \", all_posttags[:1][0][:6])\n",
    "print('Actual: ', garden_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1910da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd4ce2a1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 4.1493 - accuracy: 0.3045\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 1.9105 - accuracy: 0.3591\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 2.2415 - accuracy: 0.1773\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.4386 - accuracy: 0.2476\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.0344 - accuracy: 0.3095\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.2206 - accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "lr01_pd10 = load_model('lstm_lr0.1_bs128_p10_e20_sgd.h5')\n",
    "lr001_pd10 = load_model('lstm_lr0.01_bs128_p10_e20_sgd.h5')\n",
    "lr0001_pd10 = load_model('lstm_lr0.001_bs128_p10_e20_sgd.h5')\n",
    "lr01_pd10_res = lr01_pd10.evaluate(normal_pd, normal_pos_pd)\n",
    "lr001_pd10_res = lr001_pd10.evaluate(normal_pd, normal_pos_pd)\n",
    "lr0001_pd10_res = lr0001_pd10.evaluate(normal_pd, normal_pos_pd)\n",
    "lr01_pd10_resGarden = lr01_pd10.evaluate(garden_pd, garden_pos_pd)\n",
    "lr001_pd10_resGarden = lr001_pd10.evaluate(garden_pd, garden_pos_pd)\n",
    "lr0001_pd10_resGarden = lr0001_pd10.evaluate(garden_pd, garden_pos_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1656687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 299ms/step\n",
      "0.012727272727272728\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "0.03272727272727273\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "0.025454545454545455\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "0.006666666666666667\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.03619047619047619\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0.030476190476190476\n"
     ]
    }
   ],
   "source": [
    "prediction(lr01_pd50, 'normal')\n",
    "prediction(lr001_pd50, 'normal')\n",
    "prediction(lr0001_pd50, 'normal')\n",
    "prediction(lr01_pd50, 'garden')\n",
    "prediction(lr001_pd50, 'garden')\n",
    "prediction(lr0001_pd50, 'garden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9fd2666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 348ms/step - loss: 0.6428 - accuracy: 0.8600\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.3381 - accuracy: 0.8845\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.4920 - accuracy: 0.8818\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6908 - accuracy: 0.8524\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3450 - accuracy: 0.8838\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5062 - accuracy: 0.8781\n"
     ]
    }
   ],
   "source": [
    "lr01_pd50 = load_model('lstm_lr0.1_bs128_p50_e20_sgd.h5')\n",
    "lr001_pd50 = load_model('lstm_lr0.01_bs128_p50_e20_sgd.h5')\n",
    "lr0001_pd50 = load_model('lstm_lr0.001_bs128_p50_e20_sgd.h5')\n",
    "lr01_pd50_res = lr01_pd50.evaluate(normal_pd, normal_pos_pd)\n",
    "lr001_pd50_res = lr001_pd50.evaluate(normal_pd, normal_pos_pd)\n",
    "lr0001_pd50_res = lr0001_pd50.evaluate(normal_pd, normal_pos_pd)\n",
    "lr01_pd50_resGarden = lr01_pd50.evaluate(garden_pd, garden_pos_pd)\n",
    "lr001_pd50_resGarden = lr001_pd50.evaluate(garden_pd, garden_pos_pd)\n",
    "lr0001_pd50_resGarden = lr0001_pd50.evaluate(garden_pd, garden_pos_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa4acd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2663 - accuracy: 0.9300\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.1823 - accuracy: 0.9436\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.2543 - accuracy: 0.9323\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2827 - accuracy: 0.9257\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1869 - accuracy: 0.9424\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2624 - accuracy: 0.9310\n"
     ]
    }
   ],
   "source": [
    "lr01_pd100 = load_model('lstm_lr0.1_bs128_p100_e20_sgd.h5')\n",
    "lr001_pd100 = load_model('lstm_lr0.01_bs128_p100_e20_sgd.h5')\n",
    "lr0001_pd100 = load_model('lstm_lr0.001_bs128_p100_e20_sgd.h5')\n",
    "lr01_pd100_res = lr01_pd100.evaluate(normal_pd, normal_pos_pd)\n",
    "lr001_pd100_res = lr001_pd100.evaluate(normal_pd, normal_pos_pd)\n",
    "lr0001_pd100_res = lr0001_pd100.evaluate(normal_pd, normal_pos_pd)\n",
    "lr01_pd100_resGarden = lr01_pd100.evaluate(garden_pd, garden_pos_pd)\n",
    "lr001_pd100_resGarden = lr001_pd100.evaluate(garden_pd, garden_pos_pd)\n",
    "lr0001_pd100_resGarden = lr0001_pd100.evaluate(garden_pd, garden_pos_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "989b968c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "LSTM Model with Mask False\n",
      "Normal Sentence: \"The old man rode the boat\"\n",
      "Prediction:  [['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', 'NOUN', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', 'NOUN', 'NOUN', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', 'NOUN', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', 'NOUN', 'NOUN', 'NOUN', 'NOUN', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', 'NOUN', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', 'NOUN', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', 'NOUN', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', 'NOUN', 'NOUN', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']]\n",
      "Actual:  ['DET', 'ADJ', 'NOUN', 'VERB', 'DET', 'NOUN', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "Garden Path Sentence: \"The old man the boat\"\n",
      "Prediction:  ['', '', '', '', '', '']\n",
      "Actual:  ['DET', 'NOUN', 'VERB', 'DET', 'NOUN', '.']\n"
     ]
    }
   ],
   "source": [
    "pred = lr0001_pd100.predict(normal_pd) \n",
    "pred_vec = np.argmax(pred, axis =-1)\n",
    "label = np.argmax(normal_pos_pd,axis =-1)\n",
    "pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "\n",
    "# print(len(inds[0])/len(pred_flat))\n",
    "\n",
    "all_posttags = []\n",
    "for p in pred:\n",
    "    predseq = [np.argmax(pred, axis=-1) for pred in p]\n",
    "    pred_tags = [pos_tokenizer.sequences_to_texts([[i]])[0].upper() for i in predseq]\n",
    "    all_posttags.append(pred_tags)\n",
    "print('LSTM Model with Mask False')\n",
    "print('Normal Sentence: \"The old man rode the boat\"')\n",
    "print(\"Prediction: \", all_posttags)\n",
    "print('Actual: ', labels[0])\n",
    "\n",
    "\n",
    "pred = lr0001_pd100.predict(garden_pd) \n",
    "pred_vec = np.argmax(pred, axis =-1)\n",
    "label = np.argmax(garden_pos_pd,axis =-1)\n",
    "pred_flat, actual_flat = pred_vec.flatten(), label.flatten()\n",
    "inds = np.where((pred_flat == actual_flat) & (pred_flat != 0))\n",
    "# print(pred_vec[:5]) \n",
    "# print(label[:5])\n",
    "# print(len(inds[0])/len(pred_flat))\n",
    "\n",
    "all_posttags = []\n",
    "for p in pred:\n",
    "    predseq = [np.argmax(pred, axis=-1) for pred in p]\n",
    "    pred_tags = [pos_tokenizer.sequences_to_texts([[i]])[0].upper() for i in predseq]\n",
    "    all_posttags.append(pred_tags)\n",
    "print('Garden Path Sentence: \"The old man the boat\"')\n",
    "print(\"Prediction: \", all_posttags[:1][0][:6])\n",
    "print('Actual: ', garden_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86add1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
